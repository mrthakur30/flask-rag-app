# ðŸ§  RAG Flask â€“ GenAI & Agentic AI From Scratch

A **from-scratch Retrieval-Augmented Generation (RAG) system** built using **Flask**, **Groq LLMs**, and a **custom in-memory vector store**, without LangChain or heavy abstractions.

This project is intentionally designed for **deep understanding**, **debuggability**, and **job readiness** in GenAI / Agentic AI roles.

---

## ðŸš€ What This Project Teaches

* How RAG actually works under the hood
* How embeddings, chunking, and vector search fit together
* How LLMs are grounded using retrieved context
* How Agentic AI differs from simple chatbots
* How to structure GenAI backends like real systems

No magic. No black boxes.

---

## ðŸ—ï¸ High-Level Architecture

```
User
 â”œâ”€â”€ POST /ingest â”€â”€â–¶ Chunker â”€â–¶ Embedder â”€â–¶ Vector Store
 â””â”€â”€ POST /query  â”€â”€â–¶ Retriever â”€â–¶ Prompt Builder â”€â–¶ Groq LLM â”€â–¶ Answer
                         â–²
                         â””â”€â”€â”€â”€ Agent (decision logic)
```

Key principles:

* Clear **write path** (ingestion)
* Clear **read path** (retrieval + generation)
* Shared vector store state
* Agent controls *when* tools are used

---

## ðŸ“ Project Structure (Explained)

```
rag-flask/
â”œâ”€â”€ app.py                    # Flask entry point (API)
â”œâ”€â”€ config.py                 # App & model configuration
â”œâ”€â”€ ingest/                   # Write path (indexing)
â”‚   â”œâ”€â”€ chunker.py            # Text chunking with overlap
â”‚   â”œâ”€â”€ embedder.py           # Embedding generation
â”‚   â””â”€â”€ ingest_service.py     # Ingestion orchestration
â”œâ”€â”€ store/                    # Memory & similarity layer
â”‚   â”œâ”€â”€ vector_store.py       # Custom vector DB + cosine similarity
â”‚   â””â”€â”€ store.py              # Singleton vector store instance
â”œâ”€â”€ query/                    # Read path (RAG pipeline)
â”‚   â”œâ”€â”€ retriever.py          # Semantic search
â”‚   â”œâ”€â”€ prompt.py             # Prompt construction
â”‚   â”œâ”€â”€ groq_client.py        # Groq API wrapper
â”‚   â””â”€â”€ generate_answer.py    # RAG answer generation
â”œâ”€â”€ agent/                    # Agentic AI logic
â”‚   â””â”€â”€ simple_agent.py       # Tool-using decision loop
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â””â”€â”€ README.md
```

Each folder maps to a **real production concern**, not a framework abstraction.

---

## ðŸ§  RAG Flow (Step-by-Step)

### 1ï¸âƒ£ Ingestion

* Raw text is chunked with overlap
* Each chunk is embedded into a vector
* Vectors are stored in the vector store

Why overlap?

* Prevents semantic loss at chunk boundaries
* Improves retrieval accuracy

---

### 2ï¸âƒ£ Retrieval

* User question is embedded
* Cosine similarity finds top-K relevant chunks
* Retrieved chunks form the **grounded context**

---

### 3ï¸âƒ£ Generation

* Context + question are injected into a strict prompt
* Groq LLM generates an answer
* If context is missing â†’ model must say **"I donâ€™t know"**

This is hallucination control.

---

## ðŸ¤– Agentic AI (Important)

This project does **not** treat agents as libraries.

An agent here is:

* A control loop
* With access to tools (retriever, LLM)
* Making decisions based on state

Example reasoning:

```
If context is empty â†’ donâ€™t answer
If question is vague â†’ retrieve first
If answer already known â†’ skip retrieval
```

This mirrors real agent systems.

---

## âŒ Why No LangChain?

LangChain is intentionally avoided to:

* Understand fundamentals deeply
* Avoid hidden abstractions
* Make debugging obvious
* Explain systems clearly in interviews
* Maintain full architectural control

Frameworks can be added **after mastery**, not before.

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Create Virtual Environment

```
python -m venv venv
source venv/bin/activate  # Windows: venv\\Scripts\\activate
```

### 2ï¸âƒ£ Install Dependencies

```
pip install -r requirements.txt
```

### 3ï¸âƒ£ Set Environment Variables

```
GROQ_API_KEY=your_api_key_here
```

### 4ï¸âƒ£ Run the App

```
python app.py
```

---

## ðŸ§ª Example Usage

### Ingest

```
POST /ingest
{
  "text": "JWT tokens are stateless authentication tokens..."
}
```

### Query

```
POST /query
{
  "question": "How do JWT tokens expire?"
}
```

---

## ðŸ§‘â€ðŸ’» Skills Demonstrated

* GenAI system design
* RAG from scratch
* Vector similarity search
* Prompt engineering
* Agentic AI fundamentals
* Flask backend development
* Real-world debugging

---

## ðŸ“„ Resume-Ready Line

> Built a custom Retrieval-Augmented Generation (RAG) backend using Flask and Groq LLMs with semantic search, grounded generation, and agentic decision logic â€” without LangChain.

---

## ðŸš€ Future Extensions

* Persistent vector DB (FAISS / Qdrant)
* Streaming responses
* MCP-style tool servers
* Multi-agent collaboration
* Evaluation & observability

---

**Author:** Mukul Thakur
**Focus:** Learning-first, production-aligned GenAI engineering
