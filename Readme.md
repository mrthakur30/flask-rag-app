# ðŸ§  RAG Flask â€“ Custom GenAI & Agentic AI Backend

A **from-scratch Retrieval-Augmented Generation (RAG) system** built with **Flask**, **Groq LLMs**, and a **custom vector store**, without relying on heavy frameworks like LangChain.

This project is designed to deeply understand **GenAI fundamentals**, **RAG architecture**, and **Agentic AI concepts**, making it **interview-ready and production-aligned**.

---

## ðŸš€ Features

* âœ… Custom RAG pipeline (no LangChain)
* âœ… Text chunking with overlap
* âœ… SentenceTransformer embeddings
* âœ… In-memory vector store with cosine similarity
* âœ… Semantic retrieval (Top-K search)
* âœ… Groq-powered answer generation
* âœ… Flask API (`/ingest`, `/query`)
* âœ… Agentic AI foundations (tool-based reasoning)
* âœ… Clean, modular architecture

---

## ðŸ—ï¸ Architecture Overview

```
User
 â”œâ”€â”€ POST /ingest â”€â”€â–¶ Chunker â”€â–¶ Embedder â”€â–¶ Vector Store
 â””â”€â”€ POST /query  â”€â”€â–¶ Retriever â”€â–¶ Prompt Builder â”€â–¶ Groq LLM â”€â–¶ Answer
```

### Key Design Principles

* **Separation of concerns** (ingestion, retrieval, generation)
* **Shared singleton vector store** to avoid state bugs
* **Framework-agnostic core logic**
* **Grounded answers (hallucination control)**

---

## ðŸ“ Project Structure

```
rag-flask/
â”œâ”€â”€ app.py                     # Flask entry point
â”œâ”€â”€ ingest/
â”‚   â”œâ”€â”€ chunker.py              # Text chunking logic
â”‚   â”œâ”€â”€ embedder.py             # Embedding layer
â”‚   â””â”€â”€ ingest_service.py       # Ingestion pipeline
â”œâ”€â”€ retrieval/
â”‚   â””â”€â”€ retriever.py            # Semantic search
â”œâ”€â”€ generation/
â”‚   â”œâ”€â”€ groq_client.py          # Groq LLM wrapper
â”‚   â”œâ”€â”€ prompt.py               # Prompt construction
â”‚   â””â”€â”€ answer_generator.py     # RAG answer generation
â”œâ”€â”€ agent/
â”‚   â””â”€â”€ simple_agent.py         # Agentic AI loop
â”œâ”€â”€ store/
â”‚   â”œâ”€â”€ vector_store.py         # Custom vector DB
â”‚   â””â”€â”€ store.py                # Singleton store
â””â”€â”€ README.md
```

---

## ðŸ§  How RAG Works Here

1. **Ingestion**

   * Raw text is chunked with overlap
   * Chunks are embedded into vectors
   * Stored in a custom vector store

2. **Retrieval**

   * User query is embedded
   * Cosine similarity finds relevant chunks

3. **Generation**

   * Retrieved context is injected into prompt
   * Groq LLM generates a grounded answer
   * If context is missing â†’ "I donâ€™t know"

---

## ðŸ§ª API Usage

### ðŸ”¹ Health Check

```
GET /health
```

Response:

```json
{
  "status": "ok",
  "vectors": 5
}
```

---

### ðŸ”¹ Ingest Data

```
POST /ingest
Content-Type: application/json

{
  "text": "JWT tokens are stateless authentication tokens..."
}
```

---

### ðŸ”¹ Query

```
POST /query
Content-Type: application/json

{
  "question": "How do JWT tokens expire?"
}
```

Response:

```json
{
  "question": "How do JWT tokens expire?",
  "answer": "JWT tokens expire after a fixed duration..."
}
```

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Create Virtual Environment

```
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
```

### 2ï¸âƒ£ Install Dependencies

```
pip install flask sentence-transformers groq
```

### 3ï¸âƒ£ Set Environment Variable

```
setx GROQ_API_KEY "your_groq_api_key"
```

### 4ï¸âƒ£ Run Server

```
python app.py
```

---

## ðŸ¤– Agentic AI (STEP 9)

This project introduces **Agentic AI concepts** without frameworks:

* Tool-based reasoning
* Conditional execution
* Multi-step decision logic

Agents are implemented as **control-flow loops**, not magic abstractions.

---

## âŒ Why Not LangChain?

* Avoids hidden abstractions
* Easier debugging
* Stable core logic
* Better interview explanations
* Full control over retrieval & generation

LangChain can be added later **once fundamentals are solid**.

---

## ðŸ“Œ Known Limitations (Intentional)

* In-memory vector store (resets on restart)
* Single-process Flask app
* No authentication
* No streaming responses

These are solvable extensions.

---

## ðŸ§‘â€ðŸ’» Skills Demonstrated

* GenAI system design
* RAG fundamentals
* Vector similarity search
* Prompt engineering
* Agentic AI concepts
* Flask backend development
* Debugging real-world AI issues

---

## ðŸ“„ Resume-Ready Description

> Built a custom Retrieval-Augmented Generation (RAG) backend using Flask and Groq LLMs with semantic search, vector similarity retrieval, and agentic AI foundations â€” without relying on LangChain.

---

## ðŸš€ Next Possible Enhancements

* Persistent vector DB (FAISS / Qdrant)
* Streaming responses
* Tool calling via MCP
* Multi-agent collaboration
* Evaluation & metrics
* Authentication & rate limiting

---

**Author:** Mukul Thakur
**Purpose:** Learning-first, job-ready GenAI engineering
